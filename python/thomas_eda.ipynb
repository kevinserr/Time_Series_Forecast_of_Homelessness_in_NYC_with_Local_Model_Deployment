{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bca530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affordable demolition proportion: 0.3032128514056225\n",
      "For-profit demolition proportion: 0.27143652561247217\n",
      "Z-stat: 2.175627925063663\n",
      "P-value: 0.014791546756534511\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect('/Users/Marcy_Student/TeamHousing/data/processed/nyc_demolitions.db')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT job_typeid, ownership_id\n",
    "FROM fact_demolitions\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Create demolition indicator (2 = Demolition)\n",
    "df['is_demolition'] = (df['job_typeid'] == 2).astype(int)\n",
    "\n",
    "# Affordable = ownership_id 2 & 3\n",
    "df['is_affordable'] = df['ownership_id'].isin([2, 3]).astype(int)\n",
    "\n",
    "# Split groups\n",
    "affordable = df[df['is_affordable'] == 1]\n",
    "forprofit = df[df['is_affordable'] == 0]\n",
    "\n",
    "# Count demolitions in each group\n",
    "count = np.array([\n",
    "    affordable['is_demolition'].sum(),\n",
    "    forprofit['is_demolition'].sum()\n",
    "])\n",
    "\n",
    "# Total observations in each group\n",
    "nobs = np.array([\n",
    "    len(affordable),\n",
    "    len(forprofit)\n",
    "])\n",
    "\n",
    "# Safety check\n",
    "if np.any(nobs == 0):\n",
    "    print(\"Error: One group has zero observations.\")\n",
    "elif np.all(count == 0):\n",
    "    print(\"Error: No demolitions found in either group.\")\n",
    "else:\n",
    "    stat, p_value = proportions_ztest(count, nobs, alternative='larger')\n",
    "\n",
    "    print(\"Affordable demolition proportion:\", count[0] / nobs[0])\n",
    "    print(\"For-profit demolition proportion:\", count[1] / nobs[1])\n",
    "    print(\"Z-stat:\", stat)\n",
    "    print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fa0787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_typeid\n",
      "1    11162\n",
      "2     4202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['job_typeid'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ac003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Early Period: 42515.82142857143\n",
      "Mean Late Period: 44687.42857142857\n",
      "T-statistic: 0.9650979348362486\n",
      "One-sided P-value: 0.08463209868293742\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT report_date, shelter_count\n",
    "FROM fact_shelters\n",
    "ORDER BY report_date\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Ensure proper date format\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "\n",
    "# Split into two equal halves\n",
    "midpoint = len(df) // 2\n",
    "\n",
    "early_period = df.iloc[:midpoint]['shelter_count']\n",
    "late_period = df.iloc[midpoint:]['shelter_count']\n",
    "\n",
    "# Welch's t-test (does not assume equal variance)\n",
    "t_stat, p_two_sided = ttest_ind(late_period, early_period, equal_var=False)\n",
    "\n",
    "# Convert to one-sided (testing Late > Early)\n",
    "if t_stat > 0:\n",
    "    p_one_sided = p_two_sided / 2\n",
    "else:\n",
    "    p_one_sided = 1 - (p_two_sided / 2)\n",
    "\n",
    "print(\"Mean Early Period:\", early_period.mean())\n",
    "print(\"Mean Late Period:\", late_period.mean())\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"One-sided P-value:\", p_one_sided)\n",
    "\n",
    "# this is not optimal, only checks difference in size not time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          shelter_count   R-squared:                       0.121\n",
      "Model:                            OLS   Adj. R-squared:                  0.113\n",
      "Method:                 Least Squares   F-statistic:                     6.922\n",
      "Date:                Thu, 12 Feb 2026   Prob (F-statistic):            0.00974\n",
      "Time:                        12:04:20   Log-Likelihood:                -1202.2\n",
      "No. Observations:                 112   AIC:                             2408.\n",
      "Df Residuals:                     110   BIC:                             2414.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3.651e+04   2052.535     17.789      0.000    3.25e+04    4.05e+04\n",
      "time_index   127.7228     48.546      2.631      0.009      32.574     222.872\n",
      "==============================================================================\n",
      "Omnibus:                        9.527   Durbin-Watson:                   0.016\n",
      "Prob(Omnibus):                  0.009   Jarque-Bera (JB):                3.716\n",
      "Skew:                          -0.093   Prob(JB):                        0.156\n",
      "Kurtosis:                       2.127   Cond. No.                         128.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 1 lags and without small sample correction\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT report_date, shelter_count\n",
    "FROM fact_shelters\n",
    "ORDER BY report_date\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Convert date column properly\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "\n",
    "# Sort to ensure proper time order\n",
    "df = df.sort_values('report_date')\n",
    "\n",
    "# Create numeric time trend\n",
    "df['time_index'] = np.arange(len(df))\n",
    "\n",
    "# Define regression variables\n",
    "X = sm.add_constant(df['time_index'])\n",
    "y = df['shelter_count']\n",
    "\n",
    "# ---------\n",
    "# OLS WITH HAC STANDARD ERRORS\n",
    "# ---------\n",
    "\n",
    "model = sm.OLS(y, X).fit(\n",
    "    cov_type='HAC',\n",
    "    cov_kwds={'maxlags': 1}   # 1 lag is typical for monthly data\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f76dea",
   "metadata": {},
   "source": [
    "A linear time trend regression indicates a statistically significant upward trend in shelter counts over time. After correcting for autocorrelation using Newey–West standard errors, the estimated increase is approximately 128 individuals per period (β = 127.7, p = 0.009). This provides evidence of a sustained increase in homelessness during the sample period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7a95744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 98.98441740921045\n",
      "P-value: 2.5149106252357457e-83\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT borough, time_of_completion\n",
    "FROM fact_demolitions\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn).dropna()\n",
    "\n",
    "groups = [\n",
    "    group['time_of_completion'].values\n",
    "    for name, group in df.groupby('borough')\n",
    "]\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(*groups)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef33565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th percentile mean: 153.7583246618106\n",
      "75th percentile mean: 2816.042686100989\n",
      "T-stat: -120.53651717543569\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "query = \"SELECT time_of_completion FROM fact_demolitions\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn).dropna()\n",
    "\n",
    "q25 = df['time_of_completion'].quantile(0.25)\n",
    "q75 = df['time_of_completion'].quantile(0.75)\n",
    "\n",
    "lower = df[df['time_of_completion'] <= q25]['time_of_completion']\n",
    "upper = df[df['time_of_completion'] >= q75]['time_of_completion']\n",
    "\n",
    "t_stat, p_value = ttest_ind(lower, upper, equal_var=False)\n",
    "\n",
    "print(\"25th percentile mean:\", lower.mean())\n",
    "print(\"75th percentile mean:\", upper.mean())\n",
    "print(\"T-stat:\", t_stat)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dd466e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Early: 42515.82142857143\n",
      "Mean Late: 44687.42857142857\n",
      "T-stat: 0.9650979348362486\n",
      "One-sided P-value: 0.16926419736587484\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT report_date, shelter_count\n",
    "FROM fact_shelters\n",
    "ORDER BY report_date\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "\n",
    "midpoint = len(df) // 2\n",
    "\n",
    "early = df.iloc[:midpoint]['shelter_count']\n",
    "late = df.iloc[midpoint:]['shelter_count']\n",
    "\n",
    "t_stat, p_two = ttest_ind(late, early, equal_var=False)\n",
    "\n",
    "if t_stat > 0:\n",
    "    p_one = p_two / 2\n",
    "else:\n",
    "    p_one = 1 - (p_two / 2)\n",
    "\n",
    "print(\"Mean Early:\", early.mean())\n",
    "print(\"Mean Late:\", late.mean())\n",
    "print(\"T-stat:\", t_stat)\n",
    "print(\"One-sided P-value:\", p_one)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1b6bc",
   "metadata": {},
   "source": [
    "| Test                | What It Answers                                           |\n",
    "| ------------------- | --------------------------------------------------------- |\n",
    "| Proportion Z-test   | Is affordable ownership demolished more often?            |\n",
    "| ANOVA               | Do boroughs differ in project completion speed?           |\n",
    "| 25% vs 75% t-test   | Are fastest and slowest projects statistically different? |\n",
    "| Homelessness t-test | Has homelessness increased over time?                     |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
